{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ijxqbe0tWQp"
   },
   "source": [
    "# Chapter 6: Neural Architecture Search (NAS) - Code Examples\n",
    "\n",
    "This companion notebook contains all the code examples from Chapter 6, organized for easy experimentation and learning. It covers the fundamental concepts of NAS, from designing search spaces to implementing efficient search strategies and using practical tools.\n",
    "\n",
    "### Contents:\n",
    "1. Environment Setup and Dependencies\n",
    "2. Search Space Design\n",
    "3. Search Strategies\n",
    "4. Performance Estimation Strategies\n",
    "5. Efficient NAS Techniques\n",
    "6. Practical Tools and Applications\n",
    "7. Summary and Best Practices\n",
    "8. Final Notes and Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ncohWwytWQs"
   },
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4BSamjMtXMl"
   },
   "source": [
    "Before running this notebook, ensure you have a compatible environment. The NAS\n",
    "frameworks in this chapter require specific version combinations to work correctly.\n",
    "\n",
    "### Known Compatibility Issue\n",
    "\n",
    "TensorFlow and protobuf must use compatible versions. If you encounter:\n",
    "```\n",
    "AttributeError: 'google._upb._message.FieldDescriptor' object has no attribute 'is_repeated'\n",
    "```\n",
    "\n",
    "This means protobuf 5.x is installed, which is incompatible with TensorFlow 2.15-2.16.\n",
    "The setup cell below handles this automatically.\n",
    "\n",
    "### Recommended Setup\n",
    "\n",
    "**Option A: Conda (recommended)**\n",
    "```bash\n",
    "conda env create -f chapter6_environment.yml\n",
    "conda activate automl-ch6\n",
    "```\n",
    "\n",
    "**Option B: pip**\n",
    "```bash\n",
    "python -m venv automl-ch6\n",
    "source automl-ch6/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def check_and_fix_environment():\n",
    "    \"\"\"Check for known compatibility issues and report them.\"\"\"\n",
    "    \n",
    "    print(\"Checking environment compatibility...\\n\")\n",
    "    \n",
    "    # Check protobuf version\n",
    "    try:\n",
    "        import google.protobuf\n",
    "        pb_version = google.protobuf.__version__\n",
    "        print(f\"  protobuf: {pb_version}\")\n",
    "        \n",
    "        # Protobuf 5.x causes issues with TensorFlow\n",
    "        if pb_version.startswith(\"5.\"):\n",
    "            print(\"\\nWARNING: protobuf 5.x detected. For best compatibility, run:\")\n",
    "            print(\"  pip install 'protobuf>=4.23,<5.0'\")\n",
    "            print(\"Then restart the kernel.\\n\")\n",
    "    except ImportError:\n",
    "        print(\"  protobuf: not installed\")\n",
    "    \n",
    "    # Check TensorFlow\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        print(f\"  tensorflow: {tf.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"  tensorflow: not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"  tensorflow: error importing - {e}\")\n",
    "        print(\"\\nWARNING: TensorFlow import failed. This may be a protobuf issue.\")\n",
    "        print(\"  Try: pip install 'protobuf>=4.23,<5.0'\")\n",
    "        print(\"  Then restart the kernel.\\n\")\n",
    "    \n",
    "    # Check PyTorch\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"  pytorch: {torch.__version__}\")\n",
    "        print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "    except ImportError:\n",
    "        print(\"  pytorch: not installed\")\n",
    "    \n",
    "    print(\"\\nEnvironment check complete!\")\n",
    "\n",
    "# Run the check\n",
    "check_and_fix_environment()\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 3 (Code) - Install Missing Packages (if needed)\n",
    "# =============================================================================\n",
    "\n",
    "# Uncomment and run if packages are missing\n",
    "# Note: In Google Colab, use these install commands\n",
    "\n",
    "# !pip install torch torchvision -q\n",
    "# !pip install \"tensorflow>=2.15,<2.17\" -q\n",
    "# !pip install \"protobuf>=4.23,<5.0\" -q  # Critical: must be <5.0\n",
    "# !pip install autokeras -q\n",
    "# !pip install keras-tuner -q\n",
    "# !pip install optuna -q\n",
    "# !pip install \"ray[tune]\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0GsXj5ItWQs"
   },
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow and Keras imports (used in specific sections)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import autokeras as ak\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Ray and Optuna imports (used in specific sections)\n",
    "import optuna\n",
    "from ray import tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbXkXFGutWQt"
   },
   "source": [
    "## 2. Search Space Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESE4Y2cltWQt"
   },
   "source": [
    "### 2.1 Cell-Based Search Space with AutoKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9fKdqT-tWQu"
   },
   "outputs": [],
   "source": [
    "def create_nas_model_autokeras():\n",
    "    \"\"\"\n",
    "    Define a search space for image classification using the high-level AutoKeras API.\n",
    "    AutoKeras handles the search space internally.\n",
    "    \"\"\"\n",
    "    model = ak.ImageClassifier(\n",
    "        num_classes=10,  # Adjust based on your dataset\n",
    "        multi_label=False,\n",
    "        max_trials=10, # Number of different architectures to try\n",
    "        directory='autokeras_nas_results',\n",
    "        project_name='image_classification_nas'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "autokeras_model = create_nas_model_autokeras()\n",
    "print(\"AutoKeras model with a predefined search space created successfully!\")\n",
    "print(autokeras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DTPlC6atWQu"
   },
   "source": [
    "### 2.2 Custom Search Space with KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_tubnEftWQu"
   },
   "outputs": [],
   "source": [
    "class NASSearchSpace(kt.HyperModel):\n",
    "    \"\"\"Custom search space for Neural Architecture Search using KerasTuner.\"\"\"\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Input(shape=(32, 32, 3)))\n",
    "\n",
    "        # Search over the number of convolutional blocks\n",
    "        num_blocks = hp.Int('num_blocks', min_value=2, max_value=5, step=1)\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            filters = hp.Choice(f'filters_{i}', values=[32, 64, 128])\n",
    "            kernel_size = hp.Choice(f'kernel_size_{i}', values=[3, 5])\n",
    "            activation = hp.Choice(f'activation_{i}', values=['relu', 'swish'])\n",
    "\n",
    "            model.add(keras.layers.Conv2D(filters, kernel_size, activation=activation, padding='same'))\n",
    "\n",
    "            if hp.Boolean(f'batch_norm_{i}'):\n",
    "                model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "            if i % 2 == 1:\n",
    "                model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "        model.add(keras.layers.GlobalAveragePooling2D())\n",
    "        model.add(keras.layers.Dense(10, activation='softmax')) # Assuming 10 classes\n",
    "\n",
    "        learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "def run_keras_tuner_search(x_train, y_train, x_val, y_val):\n",
    "    \"\"\"Run Neural Architecture Search with Keras Tuner.\"\"\"\n",
    "    tuner = kt.RandomSearch(\n",
    "        NASSearchSpace(),\n",
    "        objective='val_accuracy',\n",
    "        max_trials=15,\n",
    "        directory='kerastuner_nas_results',\n",
    "        project_name='custom_nas_search'\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        x_train, y_train,\n",
    "        epochs=10,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[keras.callbacks.EarlyStopping(patience=3)]\n",
    "    )\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    return best_model, best_hyperparameters\n",
    "\n",
    "print(\"KerasTuner search space defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuqjfFtXtWQv"
   },
   "source": [
    "### 2.3 Programmatic Search Space Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVYijZ3QtWQv"
   },
   "outputs": [],
   "source": [
    "class SearchSpaceConfig:\n",
    "    \"\"\"Configuration class for defining custom search spaces programmatically.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.layer_types = ['conv', 'depthwise_conv', 'dilated_conv', 'skip_connect']\n",
    "        self.filter_sizes = [16, 32, 64, 128, 256]\n",
    "        self.kernel_sizes = [3, 5, 7]\n",
    "        self.activation_functions = ['relu', 'swish', 'gelu']\n",
    "        self.depth_range = (5, 20)\n",
    "\n",
    "    def sample_architecture(self, depth=None):\n",
    "        \"\"\"Sample a random architecture from the search space.\"\"\"\n",
    "        if depth is None:\n",
    "            depth = random.randint(*self.depth_range)\n",
    "\n",
    "        architecture = []\n",
    "        for i in range(depth):\n",
    "            layer_config = {\n",
    "                'type': random.choice(self.layer_types),\n",
    "                'filters': random.choice(self.filter_sizes),\n",
    "                'kernel_size': random.choice(self.kernel_sizes),\n",
    "                'activation': random.choice(self.activation_functions)\n",
    "            }\n",
    "            architecture.append(layer_config)\n",
    "        return architecture\n",
    "\n",
    "    def get_search_space_size(self):\n",
    "        \"\"\"Calculate the theoretical size of the search space.\"\"\"\n",
    "        choices_per_layer = (len(self.layer_types) * len(self.filter_sizes) * \\\n",
    "                           len(self.kernel_sizes) * len(self.activation_functions))\n",
    "\n",
    "        total_size = sum(choices_per_layer ** d for d in range(*self.depth_range))\n",
    "        return total_size\n",
    "\n",
    "# Example usage:\n",
    "search_config = SearchSpaceConfig()\n",
    "sample_arch = search_config.sample_architecture(depth=10)\n",
    "print(f\"Sampled Architecture (first 3 layers): {sample_arch[:3]}...\")\n",
    "print(f\"Theoretical Search Space Size: {search_config.get_search_space_size():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9VSQabCtWQv"
   },
   "source": [
    "## 3. Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM1cFJPCtWQv"
   },
   "source": [
    "### 3.1 Evolutionary Neural Architecture Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmYFAqjZtWQv"
   },
   "outputs": [],
   "source": [
    "def evaluate_architecture_placeholder(architecture):\n",
    "    \"\"\"Placeholder evaluation function. In practice, this would train the model.\"\"\"\n",
    "    score = 0.5  # Base score\n",
    "    # Reward skip connections and modern activations\n",
    "    score += sum(1 for l in architecture if l['type'] == 'skip_connect') * 0.02\n",
    "    score += sum(1 for l in architecture if l['activation'] in ['swish', 'gelu']) * 0.01\n",
    "    # Penalize overly deep or shallow networks\n",
    "    if 8 <= len(architecture) <= 15: score += 0.1\n",
    "    score += random.gauss(0, 0.05) # Simulate training variance\n",
    "    return max(0, min(1, score))\n",
    "\n",
    "def mutate_architecture(architecture, search_config, mutation_rate=0.3):\n",
    "    \"\"\"Mutate an architecture by randomly changing some layers.\"\"\"\n",
    "    mutated = []\n",
    "    for layer in architecture:\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated.append(search_config.sample_architecture(depth=1)[0])\n",
    "        else:\n",
    "            mutated.append(layer.copy())\n",
    "    return mutated\n",
    "\n",
    "def evolutionary_nas(population_size=50, generations=20, search_config=None):\n",
    "    \"\"\"Simplified evolutionary NAS implementation.\"\"\"\n",
    "    search_config = search_config or SearchSpaceConfig()\n",
    "    print(\"Starting Evolutionary NAS...\")\n",
    "\n",
    "    # Initialize population\n",
    "    population = [search_config.sample_architecture() for _ in range(population_size)]\n",
    "    fitness_history = []\n",
    "\n",
    "    for gen in range(generations):\n",
    "        fitness_scores = [evaluate_architecture_placeholder(arch) for arch in population]\n",
    "        fitness_history.append(max(fitness_scores))\n",
    "\n",
    "        # Select top 50% as survivors\n",
    "        combined = sorted(zip(population, fitness_scores), key=lambda x: x[1], reverse=True)\n",
    "        survivors = [arch for arch, _ in combined[:population_size // 2]]\n",
    "\n",
    "        # Create next generation via mutation\n",
    "        new_population = survivors + [mutate_architecture(p, search_config) for p in survivors]\n",
    "        population = new_population\n",
    "\n",
    "        if gen % 5 == 0:\n",
    "            print(f\"  Generation {gen}: Best fitness = {max(fitness_scores):.4f}\")\n",
    "\n",
    "    final_scores = [evaluate_architecture_placeholder(arch) for arch in population]\n",
    "    best_arch = population[np.argmax(final_scores)]\n",
    "    print(f\"Finished! Best architecture has {len(best_arch)} layers.\")\n",
    "    return best_arch, fitness_history\n",
    "\n",
    "# Example usage:\n",
    "best_arch_evo, history_evo = evolutionary_nas(population_size=20, generations=50)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjJELtu0tWQv"
   },
   "source": [
    "### 3.2 Differentiable Architecture Search (DARTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj6zVkR8tWQw"
   },
   "outputs": [],
   "source": [
    "class MixedOperation(nn.Module):\n",
    "    \"\"\"A mixed operation that combines multiple candidate operations via learnable weights.\"\"\"\n",
    "    def __init__(self, channels, operations=['conv3', 'conv5', 'maxpool', 'skip']):\n",
    "        super().__init__()\n",
    "        self.ops = nn.ModuleList()\n",
    "        for op_name in operations:\n",
    "            if op_name == 'conv3': op = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
    "            elif op_name == 'conv5': op = nn.Conv2d(channels, channels, 5, padding=2, bias=False)\n",
    "            elif op_name == 'maxpool': op = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "            elif op_name == 'skip': op = nn.Identity()\n",
    "            else: raise ValueError(f\"Unknown op: {op_name}\")\n",
    "            self.ops.append(op)\n",
    "        self.weights = nn.Parameter(torch.randn(len(operations)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights_sm = F.softmax(self.weights, dim=0)\n",
    "        return sum(w * op(x) for w, op in zip(weights_sm, self.ops))\n",
    "\n",
    "class DARTSCell(nn.Module):\n",
    "    \"\"\"A DARTS cell that searches over a DAG of mixed operations.\"\"\"\n",
    "    def __init__(self, channels=16, num_nodes=4):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.operations = ['conv3', 'conv5', 'maxpool', 'skip']\n",
    "        self.mixed_ops = nn.ModuleList()\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i + 2):\n",
    "                self.mixed_ops.append(MixedOperation(channels, self.operations))\n",
    "\n",
    "    def forward(self, s0, s1):\n",
    "        states = [s0, s1]\n",
    "        op_idx = 0\n",
    "        for i in range(self.num_nodes):\n",
    "            node_out = sum(self.mixed_ops[op_idx+j](s) for j, s in enumerate(states))\n",
    "            op_idx += len(states)\n",
    "            states.append(node_out)\n",
    "        return torch.cat(states[-self.num_nodes:], dim=1)\n",
    "\n",
    "# Simplified DARTS network for demonstration\n",
    "class DARTSNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=10, channels=16, num_cells=3, num_nodes=4):\n",
    "        super().__init__()\n",
    "        self.stem0 = nn.Conv2d(3, channels, 3, padding=1)\n",
    "        self.stem1 = nn.Conv2d(3, channels, 3, padding=1)\n",
    "        self.cells = nn.ModuleList([DARTSCell(channels, num_nodes) for _ in range(num_cells)])\n",
    "        # Project channels*num_nodes back to channels between cells\n",
    "        self.channel_projections = nn.ModuleList([\n",
    "            nn.Conv2d(channels * num_nodes, channels, 1) for _ in range(num_cells - 1)\n",
    "        ])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # Final cell output has channels*num_nodes channels\n",
    "        self.classifier = nn.Linear(channels * num_nodes, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s0 = self.stem0(x)\n",
    "        s1 = self.stem1(x)\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            s0, s1 = s1, cell(s0, s1)\n",
    "            if i < len(self.channel_projections):\n",
    "                s1 = self.channel_projections[i](s1)\n",
    "        out = self.pool(s1).view(s1.size(0), -1)\n",
    "        return self.classifier(out)\n",
    "\n",
    "# Example usage:\n",
    "darts_model = DARTSNetwork()\n",
    "print(f\"DARTS model created with {sum(p.numel() for p in darts_model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjApL8EhtWQw"
   },
   "source": [
    "## 4. Performance Estimation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8j6_4TtWQw"
   },
   "source": [
    "### 4.1 Successive Halving for Multi-fidelity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-pn5DLftWQw"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_placeholder(architecture, epochs):\n",
    "    \"\"\"Placeholder for training. Performance improves with more epochs.\"\"\"\n",
    "    time.sleep(0.005 * epochs)  # Simulate training time\n",
    "    base_score = evaluate_architecture_placeholder(architecture)\n",
    "    epoch_bonus = 0.15 * (1 - np.exp(-epochs / 40.0))\n",
    "    final_score = min(1.0, base_score + epoch_bonus)\n",
    "    return max(0, final_score + random.gauss(0, 0.02))\n",
    "\n",
    "def successive_halving_nas(architectures, max_epochs=81, reduction_factor=3):\n",
    "    \"\"\"Implement Successive Halving for efficient architecture evaluation.\"\"\"\n",
    "    print(f\"Starting Successive Halving with {len(architectures)} candidates...\")\n",
    "    candidates = architectures.copy()\n",
    "    epochs = max_epochs // (reduction_factor ** (int(np.log(len(architectures))/np.log(reduction_factor))))\n",
    "\n",
    "    round_num = 1\n",
    "    while len(candidates) > 1 and epochs <= max_epochs:\n",
    "        print(f\"\\n  Round {round_num}: Evaluating {len(candidates)} candidates for {epochs} epochs\")\n",
    "        results = [(arch, train_and_evaluate_placeholder(arch, epochs)) for arch in candidates]\n",
    "\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        keep_count = max(1, len(results) // reduction_factor)\n",
    "        candidates = [arch for arch, _ in results[:keep_count]]\n",
    "\n",
    "        print(f\"    Best score: {results[0][1]:.4f}. Keeping top {keep_count} candidates.\")\n",
    "        epochs *= reduction_factor\n",
    "        round_num += 1\n",
    "\n",
    "    print(f\"\\nSuccessive Halving finished. Best architecture found:\")\n",
    "    return candidates[0] if candidates else None\n",
    "\n",
    "# Example usage:\n",
    "search_config_sh = SearchSpaceConfig()\n",
    "sample_architectures_sh = [search_config_sh.sample_architecture() for _ in range(27)]\n",
    "best_architecture_sh = successive_halving_nas(sample_architectures_sh, max_epochs=81, reduction_factor=3)\n",
    "print(f\"  - Depth: {len(best_architecture_sh)}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIH7AEchtWQw"
   },
   "source": [
    "### 4.2 One-Shot Architecture Search (Weight Sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36pdcBLHtWQw"
   },
   "outputs": [],
   "source": [
    "class Supernet(nn.Module):\n",
    "    \"\"\"Supernet for one-shot NAS, containing all possible operations and sharing weights.\"\"\"\n",
    "    def __init__(self, search_config, num_classes=10, max_depth=10, channels=32):\n",
    "        super().__init__()\n",
    "        self.max_depth = max_depth\n",
    "        self.stem = nn.Conv2d(3, channels, 3, padding=1)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(max_depth):\n",
    "            layer_ops = nn.ModuleDict()\n",
    "            for op_type in search_config.layer_types:\n",
    "                if op_type == 'skip_connect':\n",
    "                    layer_ops[op_type] = nn.Identity()\n",
    "                else:\n",
    "                    # Simplified: all convs have same kernel size here\n",
    "                    layer_ops[op_type] = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "            self.layers.append(layer_ops)\n",
    "        self.head = nn.Linear(channels, num_classes)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x, architecture):\n",
    "        \"\"\"Forward pass using a specific architecture path.\"\"\"\n",
    "        x = self.stem(x)\n",
    "        for i, layer_config in enumerate(architecture):\n",
    "            if i < self.max_depth:\n",
    "                op_type = layer_config['type']\n",
    "                x = self.layers[i][op_type](x)\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        return self.head(x)\n",
    "\n",
    "def evaluate_architecture_fast(supernet, architecture, test_loader):\n",
    "    \"\"\"Evaluate an architecture quickly using the pre-trained supernet weights.\"\"\"\n",
    "    supernet.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            outputs = supernet(data, architecture)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Example usage:\n",
    "search_config_os = SearchSpaceConfig()\n",
    "supernet_os = Supernet(search_config_os)\n",
    "sample_arch_os = search_config_os.sample_architecture(depth=5)\n",
    "print(f\"Supernet created with {sum(p.numel() for p in supernet_os.parameters()):,} parameters.\")\n",
    "print(\"A single training run on the Supernet enables fast evaluation of many sub-architectures.\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nogP-udHtWQw"
   },
   "source": [
    "### 4.3 Learning Curve Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y590PbiMtWQw"
   },
   "outputs": [],
   "source": [
    "def exponential_curve(x, a, b, c):\n",
    "    \"\"\"Exponential saturation curve for fitting learning curves.\"\"\"\n",
    "    return a * (1 - np.exp(-b * x)) + c\n",
    "\n",
    "def predict_final_accuracy(early_accuracies, target_epochs, plot=False):\n",
    "    \"\"\"Predict final accuracy from early training epochs.\"\"\"\n",
    "    if len(early_accuracies) < 3: return early_accuracies[-1]\n",
    "    epochs = np.arange(1, len(early_accuracies) + 1)\n",
    "    try:\n",
    "        params, _ = curve_fit(exponential_curve, epochs, early_accuracies,\n",
    "                                p0=[max(early_accuracies), 0.1, min(early_accuracies)], maxfev=1000)\n",
    "        predicted = min(1.0, exponential_curve(target_epochs, *params))\n",
    "        if plot:\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.plot(epochs, early_accuracies, 'bo', label='Observed')\n",
    "            extended_epochs = np.linspace(1, target_epochs, 100)\n",
    "            plt.plot(extended_epochs, exponential_curve(extended_epochs, *params), 'r-', label='Fitted Curve')\n",
    "            plt.axhline(y=predicted, color='r', linestyle='--', label=f'Predicted Acc: {predicted:.3f}')\n",
    "            plt.title('Learning Curve Extrapolation')\n",
    "            plt.xlabel('Epochs'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True); plt.show()\n",
    "        return predicted\n",
    "    except Exception:\n",
    "        return early_accuracies[-1]\n",
    "\n",
    "# Simulate a learning curve\n",
    "true_final_acc = 0.85\n",
    "simulated_curve = true_final_acc * (1 - np.exp(-np.arange(1, 21) / 8)) + np.random.normal(0, 0.02, 20)\n",
    "\n",
    "# Predict from first 5 epochs\n",
    "predicted_acc = predict_final_accuracy(simulated_curve[:5], target_epochs=20, plot=True)\n",
    "print(f\"Predicted Final Accuracy: {predicted_acc:.3f}\")\n",
    "print(f\"True Final Accuracy: {simulated_curve[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2JLY88StWQw"
   },
   "source": [
    "### 4.4 Zero-Cost Proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PUzGkq2tWQw"
   },
   "outputs": [],
   "source": [
    "def snip_score(model, data_sample):\n",
    "    \"\"\"Compute SNIP score (gradient magnitude) for architecture ranking.\"\"\"\n",
    "    model.train()\n",
    "    data, targets = data_sample\n",
    "    outputs = model(data)\n",
    "    loss = F.cross_entropy(outputs, targets)\n",
    "    grads = torch.autograd.grad(loss, model.parameters(), create_graph=False)\n",
    "    return sum(torch.sum(torch.abs(g)) for g in grads if g is not None).item()\n",
    "\n",
    "def connectivity_proxy(architecture):\n",
    "    \"\"\"Measure architecture connectivity as a simple proxy for performance.\"\"\"\n",
    "    skips = sum(1 for layer in architecture if layer['type'] == 'skip_connect')\n",
    "    return skips / max(1, len(architecture))\n",
    "\n",
    "class ZeroCostFilter:\n",
    "    \"\"\"Multi-proxy filter for rapid architecture screening.\"\"\"\n",
    "    def filter_architectures(self, architectures, keep_fraction=0.1):\n",
    "        scores = [connectivity_proxy(arch) for arch in architectures]\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        keep_count = int(len(architectures) * keep_fraction)\n",
    "        return [architectures[i] for i in sorted_indices[:keep_count]]\n",
    "\n",
    "# Example usage:\n",
    "zc_filter = ZeroCostFilter()\n",
    "search_config_zc = SearchSpaceConfig()\n",
    "sample_architectures_zc = [search_config_zc.sample_architecture() for _ in range(1000)]\n",
    "filtered_archs_zc = zc_filter.filter_architectures(sample_architectures_zc, keep_fraction=0.1)\n",
    "print(f\"Zero-cost proxies filtered {len(sample_architectures_zc)} archs down to {len(filtered_archs_zc)}.\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84laSdfEtWQx"
   },
   "source": [
    "## 5. Efficient NAS Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2G37My1PtWQx"
   },
   "source": [
    "### 5.1 Supernet Training with Balanced Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5FRYealtWQx"
   },
   "outputs": [],
   "source": [
    "class CorrectSupernet(nn.Module):\n",
    "    \"\"\"A Supernet containing multiple choices for each layer, with corrected channel sizes.\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CorrectSupernet, self).__init__()\n",
    "        self.conv1_choices = nn.ModuleDict({'conv3x3': nn.Conv2d(3, 16, 3, p=1), 'conv5x5': nn.Conv2d(3, 16, 5, p=2)})\n",
    "        self.conv2_choices = nn.ModuleDict({'conv3x3': nn.Conv2d(16, 32, 3, p=1), 'skip_connect': nn.Conv2d(16, 32, 1)})\n",
    "        self.conv3_choices = nn.ModuleDict({'conv3x3': nn.Conv2d(32, 64, 3, p=1), 'conv1x1': nn.Conv2d(32, 64, 1)})\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(64 * 4 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x, architecture):\n",
    "        op1 = self.conv1_choices[architecture[0]]\n",
    "        x = self.pool(F.relu(op1(x)))\n",
    "        op2 = self.conv2_choices[architecture[1]]\n",
    "        x = self.pool(F.relu(op2(x)))\n",
    "        op3 = self.conv3_choices[architecture[2]]\n",
    "        x = self.pool(F.relu(op3(x)))\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "def train_supernet_balanced(supernet, data_loader, epochs=5):\n",
    "    \"\"\"Trains the supernet by uniformly sampling architectures.\"\"\"\n",
    "    optimizer = torch.optim.Adam(supernet.parameters(), lr=1e-3)\n",
    "    choices = [['conv3x3', 'conv5x5'], ['conv3x3', 'skip_connect'], ['conv3x3', 'conv1x1']]\n",
    "    supernet.train()\n",
    "    print(\"Training Supernet with balanced sampling...\")\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, target) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # Uniformly sample a random architecture for this batch\n",
    "            arch = [random.choice(c) for c in choices]\n",
    "            output = supernet(data, arch)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0: print(f\"  Epoch {epoch}, Batch {i}, Loss: {loss.item():.4f}\")\n",
    "    print(\"Supernet training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x-vAcqEtWQx"
   },
   "source": [
    "### 5.2 Once-For-All (OFA) Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ctmhu-BCtWQx"
   },
   "outputs": [],
   "source": [
    "class OFABlock(nn.Module):\n",
    "    \"\"\"An OFA block with elastic kernel size.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        # Store conv layers for each kernel size\n",
    "        self.conv_k3 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1, bias=False)\n",
    "        self.conv_k5 = nn.Conv2d(in_channels, out_channels, 5, stride, padding=2, bias=False)\n",
    "        self.conv_k7 = nn.Conv2d(in_channels, out_channels, 7, stride, padding=3, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x, kernel_size=7):\n",
    "        if kernel_size == 7:\n",
    "            out = self.conv_k7(x)\n",
    "        elif kernel_size == 5:\n",
    "            out = self.conv_k5(x)\n",
    "        elif kernel_size == 3:\n",
    "            out = self.conv_k3(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported kernel size: {kernel_size}\")\n",
    "        return F.relu(self.bn(out))\n",
    "\n",
    "class OFANetwork(nn.Module):\n",
    "    \"\"\"A simplified OFA network with elastic kernel sizes.\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.block1 = OFABlock(3, 64, stride=2)\n",
    "        self.block2 = OFABlock(64, 128, stride=2)\n",
    "        self.block3 = OFABlock(128, 256, stride=2)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x, config):\n",
    "        x = self.block1(x, config['k1'])\n",
    "        x = self.block2(x, config['k2'])\n",
    "        x = self.block3(x, config['k3'])\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def extract_subnet(self, efficiency_level='medium'):\n",
    "        if efficiency_level == 'mobile': return {'k1': 3, 'k2': 3, 'k3': 3}\n",
    "        if efficiency_level == 'medium': return {'k1': 5, 'k2': 3, 'k3': 5}\n",
    "        if efficiency_level == 'server': return {'k1': 7, 'k2': 7, 'k3': 5}\n",
    "\n",
    "# Example usage\n",
    "ofa_net = OFANetwork()\n",
    "print(\"OFA Network created. Can now be trained once.\")\n",
    "\n",
    "mobile_config = ofa_net.extract_subnet('mobile')\n",
    "server_config = ofa_net.extract_subnet('server')\n",
    "\n",
    "print(f\"Mobile Subnet Config: {mobile_config}\")\n",
    "print(f\"Server Subnet Config: {server_config}\")\n",
    "\n",
    "# After one-time training, different subnets can be deployed without retraining\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "mobile_output = ofa_net(dummy_input, mobile_config)\n",
    "server_output = ofa_net(dummy_input, server_config)\n",
    "print(\"Successfully extracted and used two different subnets from the same OFA network.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKl9nq8StWQx"
   },
   "source": [
    "### 5.3 Progressive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6YKt1-CtWQx"
   },
   "outputs": [],
   "source": [
    "class ProgressiveNAS:\n",
    "    \"\"\"Progressive NAS that starts simple and gradually increases complexity.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.stages = [\n",
    "            {'name': 'Basic', 'depth': 5, 'ops': ['conv', 'skip_connect'], 'filters': 64, 'trials': 10},\n",
    "            {'name': 'Intermediate', 'depth': 10, 'ops': ['conv', 'depthwise_conv', 'skip_connect'], 'filters': 128, 'trials': 15},\n",
    "            {'name': 'Advanced', 'depth': 15, 'ops': ['conv', 'depthwise_conv', 'dilated_conv', 'skip_connect'], 'filters': 256, 'trials': 20}\n",
    "        ]\n",
    "\n",
    "    def run_search(self):\n",
    "        print(\"Starting Progressive NAS...\")\n",
    "        best_arch = None\n",
    "        best_score = 0\n",
    "\n",
    "        for stage in self.stages:\n",
    "            print(f\"\\n  === Stage: {stage['name']} ===\")\n",
    "            stage_best_score = 0\n",
    "            # Create a search space config for the current stage\n",
    "            stage_config = SearchSpaceConfig()\n",
    "            stage_config.depth_range = (3, stage['depth'])\n",
    "            stage_config.layer_types = stage['ops']\n",
    "            stage_config.filter_sizes = [f for f in stage_config.filter_sizes if f <= stage['filters']]\n",
    "\n",
    "            for i in range(stage['trials']):\n",
    "                arch = stage_config.sample_architecture()\n",
    "                score = evaluate_architecture_placeholder(arch)\n",
    "                if score > stage_best_score:\n",
    "                    stage_best_score = score\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_arch = arch\n",
    "            print(f\"    Best score in stage: {stage_best_score:.4f}\")\n",
    "\n",
    "        print(f\"\\nProgressive search finished. Final best score: {best_score:.4f}\")\n",
    "        return best_arch, best_score\n",
    "\n",
    "# Example usage\n",
    "progressive_searcher = ProgressiveNAS()\n",
    "best_arch_prog, best_score_prog = progressive_searcher.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxaWGP4ftWQx"
   },
   "source": [
    "## 6. Practical Tools and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I31gXqJYtWQx"
   },
   "source": [
    "### 6.1 AutoKeras Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Th7q-YlxtWQx"
   },
   "outputs": [],
   "source": [
    "def autokeras_image_classification_example():\n",
    "    \"\"\"Example using AutoKeras for a complete NAS pipeline on CIFAR-10.\"\"\"\n",
    "    try:\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "        print(f\"CIFAR-10 data loaded. Train shape: {x_train.shape}\")\n",
    "\n",
    "        # Initialize the AutoKeras Image Classifier\n",
    "        clf = ak.ImageClassifier(\n",
    "            max_trials=10,  # Number of models to test\n",
    "            project_name='autokeras_cifar10_demo',\n",
    "            overwrite=True\n",
    "        )\n",
    "\n",
    "        print(\"\\nStarting AutoKeras architecture search...\")\n",
    "        clf.fit(x_train, y_train, epochs=5, validation_split=0.15)\n",
    "\n",
    "        # Evaluate the best model\n",
    "        loss, acc = clf.evaluate(x_test, y_test)\n",
    "        print(f\"\\nAutoKeras Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "        # Export the best Keras model\n",
    "        print(\"Exporting the best model...\")\n",
    "        exported_model = clf.export_model()\n",
    "        exported_model.summary()\n",
    "        return clf, exported_model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during AutoKeras example: {e}\")\n",
    "        print(\"Please ensure 'autokeras' and 'tensorflow' are installed.\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # This example is computationally intensive and is best run in a dedicated environment.\n",
    "    print(\"Skipping AutoKeras example in this run. Uncomment to execute.\")\n",
    "    # autokeras_clf, autokeras_best_model = autokeras_image_classification_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KDq07qgtWQx"
   },
   "source": [
    "### 6.2 Optuna Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQxVV8lctWQx"
   },
   "outputs": [],
   "source": [
    "def build_model_optuna(trial):\n",
    "    \"\"\"Builds a Keras model based on Optuna trial suggestions.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(28, 28, 1))) # Fashion-MNIST\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    for i in range(num_layers):\n",
    "        model.add(layers.Conv2D(\n",
    "            filters=trial.suggest_categorical(f\"filters_l{i}\", [16, 32, 64]),\n",
    "            kernel_size=trial.suggest_categorical(f\"kernel_l{i}\", [3, 5]),\n",
    "            activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def objective_optuna(trial):\n",
    "    \"\"\"Objective function for Optuna to optimize.\"\"\"\n",
    "    keras.backend.clear_session()\n",
    "    model = build_model_optuna(trial)\n",
    "    (x_train, y_train), (x_val, y_val) = keras.datasets.fashion_mnist.load_data()\n",
    "    x_train = (x_train.astype(\"float32\") / 255.0)[:10000, ..., np.newaxis]\n",
    "    y_train = y_train[:10000]\n",
    "    x_val = (x_val.astype(\"float32\") / 255.0)[..., np.newaxis]\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=4, batch_size=128, verbose=0)\n",
    "    return history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "def optuna_nas_example():\n",
    "    print(\"\\nStarting Optuna NAS example...\")\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"keras_nas_optuna\")\n",
    "    study.optimize(objective_optuna, n_trials=15, timeout=600)\n",
    "    print(f\"\\nOptuna search complete. Best validation accuracy: {study.best_value:.4f}\")\n",
    "    print(f\"  Best architecture params: {study.best_params}\")\n",
    "    return study\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Uncomment to run (takes 10+ minutes):\n",
    "    # optuna_study = optuna_nas_example()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnX4WkIRtWQy"
   },
   "source": [
    "### 6.3 Ray Tune Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWfzh9rOtWQy"
   },
   "outputs": [],
   "source": [
    "def ray_tune_trainable(config):\n",
    "    \"\"\"Training function compatible with Ray Tune.\"\"\"\n",
    "    # Build model from config\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(28, 28, 1)))\n",
    "    for _ in range(config[\"num_layers\"]):\n",
    "        model.add(layers.Conv2D(config[\"filters\"], 3, activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    (x_train, y_train), (x_val, y_val) = keras.datasets.fashion_mnist.load_data()\n",
    "    x_train = (x_train.astype(\"float32\") / 255.0)[:10000, ..., np.newaxis]\n",
    "    y_train = y_train[:10000]\n",
    "    x_val = (x_val.astype(\"float32\") / 255.0)[..., np.newaxis]\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Report metrics back to Ray Tune\n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, batch_size=128, verbose=0,\n",
    "              callbacks=[tune.integration.keras.TuneReportCallback({\"val_accuracy\": \"val_accuracy\"})])\n",
    "\n",
    "def ray_tune_nas_example():\n",
    "    \"\"\"Example of NAS using Ray Tune.\"\"\"\n",
    "    print(\"\\nStarting Ray Tune NAS example...\")\n",
    "    search_space = {\n",
    "        \"num_layers\": tune.grid_search([1, 2, 3]),\n",
    "        \"filters\": tune.choice([16, 32, 64])\n",
    "    }\n",
    "    tuner = tune.Tuner(\n",
    "        ray_tune_trainable,\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_accuracy\",\n",
    "            mode=\"max\",\n",
    "            num_samples=1 # Since we use grid search, num_samples is 1 per grid point\n",
    "        )\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"val_accuracy\", mode=\"max\")\n",
    "    print(f\"\\nRay Tune search complete. Best validation accuracy: {best_result.metrics['val_accuracy']:.4f}\")\n",
    "    print(f\"  Best config: {best_result.config}\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This example requires Ray to be initialized.\n",
    "    # It's recommended to run this in a script rather than a notebook for stability.\n",
    "    print(\"Skipping Ray Tune example. It's best run in a separate Python script.\")\n",
    "    # ray_results = ray_tune_nas_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_k4ClrdtWQy"
   },
   "source": [
    "### 6.4 Complete NAS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXN4O0xFtWQ3"
   },
   "outputs": [],
   "source": [
    "class CompletePipeLineNAS:\n",
    "    \"\"\"Complete NAS pipeline combining zero-cost proxies and multi-fidelity evaluation.\"\"\"\n",
    "    def __init__(self, search_config=None):\n",
    "        self.search_config = search_config or SearchSpaceConfig()\n",
    "        self.zero_cost_filter = ZeroCostFilter()\n",
    "\n",
    "    def run_complete_search(self, initial_candidates=500, filter_keep_frac=0.1, max_epochs=27):\n",
    "        print(f\"Starting complete NAS pipeline...\")\n",
    "\n",
    "        # Stage 1: Generate and filter candidates\n",
    "        print(f\"\\n--- Stage 1: Candidate Generation & Filtering ---\")\n",
    "        candidates = [self.search_config.sample_architecture() for _ in range(initial_candidates)]\n",
    "        filtered_candidates = self.zero_cost_filter.filter_architectures(candidates, keep_fraction=filter_keep_frac)\n",
    "        print(f\"  Generated {initial_candidates} candidates, filtered to {len(filtered_candidates)} with zero-cost proxies.\")\n",
    "\n",
    "        # Stage 2: Multi-fidelity evaluation\n",
    "        print(f\"\\n--- Stage 2: Multi-Fidelity Evaluation (Successive Halving) ---\")\n",
    "        best_arch = successive_halving_nas(filtered_candidates, max_epochs=max_epochs, reduction_factor=3)\n",
    "\n",
    "        # Stage 3: Final validation (placeholder)\n",
    "        print(f\"\\n--- Stage 3: Final Validation ---\")\n",
    "        final_score = train_and_evaluate_placeholder(best_arch, epochs=max_epochs*2)\n",
    "        print(f\"  Re-trained best architecture. Final estimated score: {final_score:.4f}\")\n",
    "\n",
    "        return best_arch, final_score\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Uncomment to run (takes 10+ minutes):\n",
    "    # pipeline = CompletePipeLineNAS()\n",
    "    # final_arch, final_score = pipeline.run_complete_search()\n",
    "    pass\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fKP2tlXtWQ3"
   },
   "source": [
    "## 7. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeeh_HSFtWQ3"
   },
   "source": [
    "This notebook provided a comprehensive overview of Neural Architecture Search (NAS) concepts and implementations.\n",
    "\n",
    "**Key Best Practices:**\n",
    "\n",
    "* **Start with High-Level Tools**: For most applications, tools like `AutoKeras` provide a powerful and easy-to-use entry point to NAS without needing to manage the search process manually.\n",
    "\n",
    "* **Define a Good Search Space**: The quality of a NAS result is heavily dependent on the search space. Ensure it contains a diverse yet reasonable set of operations. Avoid making it astronomically large.\n",
    "\n",
    "* **Use Efficient Performance Estimation**: Full training of every candidate is infeasible. Leverage techniques like:\n",
    "    * **Successive Halving / HyperBand**: To quickly discard poorly performing architectures.\n",
    "    * **Weight Sharing (One-Shot/DARTS)**: To amortize the cost of training over many architectures.\n",
    "    * **Zero-Cost Proxies**: To perform a rapid initial filtering of a large number of candidates before any training.\n",
    "\n",
    "* **Progressive Search**: Don't try to find the perfect, 50-layer network from scratch. Start the search with simpler, shallower architectures and progressively increase the complexity. This makes the search more tractable.\n",
    "\n",
    "* **Leverage Practical Frameworks**: Instead of implementing complex search algorithms from scratch, use robust libraries like `Optuna` or `Ray Tune` to handle the hyperparameter optimization and trial scheduling aspects of NAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZKGyl6QtWQ3"
   },
   "source": [
    "## 8. Final Notes and Additional Resources\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "This notebook has provided implementations for key NAS concepts:\n",
    "\n",
    "? **Search Space Design** (Programmatic, KerasTuner)  \n",
    "? **Search Strategies** (Evolutionary, Differentiable/DARTS)  \n",
    "? **Performance Estimation** (Successive Halving, One-Shot, Proxies)  \n",
    "? **Efficient NAS Techniques** (OFA, Progressive Search)  \n",
    "? **Integration with Practical Tools** (AutoKeras, Optuna, Ray Tune)  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Apply to Your Data**: Adapt the `AutoKeras` or `KerasTuner` examples to your own datasets.\n",
    "2. **Implement a Real Evaluation Function**: Replace the `evaluate_architecture_placeholder` and `train_and_evaluate_placeholder` functions with actual model training on your data to get meaningful results.\n",
    "3. **Experiment with Search Strategies**: Compare the results of a random search, evolutionary search, and a more guided search using Optuna on the same problem.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **AutoML Book (Chapter 6)**: For detailed explanations of the concepts covered here.\n",
    "- **DARTS Paper**: [Differentiable Architecture Search](https://arxiv.org/abs/1806.09055)\n",
    "- **OFA Paper**: [Once-for-All: Train One Network and Specialize it for Efficient Deployment](https://arxiv.org/abs/1908.09791)\n",
    "- **Optuna Documentation**: https://optuna.readthedocs.io/\n",
    "- **Ray Tune Documentation**: https://docs.ray.io/en/latest/tune/index.html\n",
    "\n",
    "**Happy architecture searching!** AutoML continues to make designing state-of-the-art neural networks more accessible. ??"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "automl-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}